library("tm")
library("RWeka")
massive <- readLines("final/en_US/en_US.news.txt", n=1000)
myCorpus <- Corpus(VectorSource(massive))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, PlainTextDocument)
print("OK")
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
UnigramTokenizer <- function(x) WordTokenizer(x)
tdm <- TermDocumentMatrix(myCorpus, control = list(tokenize = UnigramTokenizer))
